{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03e5e70a-0fb0-4b30-8af2-ee3e02b50009",
   "metadata": {},
   "source": [
    "Esercizio \n",
    "Dal database AdventureWorks estraiamo la tabella dimproduct \n",
    "• Sulla colonna DealerPrice, utilizzando il metodo .round(), arrotondiamo i valori alle due cifre decimali, e poi al valore intero più vicino \n",
    "• Utilizzando il metodo .clip(), facciamo in modo che i valori siano compresi tra un minimo di 0 e un massimo di 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f893be7-4e93-4bfc-a508-2928dbef3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f025626-fd43-41bb-a8c5-6769e77ee842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv(override=True, dotenv_path=\"credenziali.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb211f6-af5a-4553-9a1f-d41011b75cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getenv('username')\n",
    "password = os.getenv('password')\n",
    "host = os.getenv('host')\n",
    "dbname = os.getenv('dbname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b878e70-4af1-4a7f-92a9-19fa5c42d1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysql+pymysql://studente_dapt:Ep1c0d3!!D4t4**4n4lys1s@epicode-data-pt-mysql.cvetyjye2qbl.eu-central-1.rds.amazonaws.com/AdventureWorks\n"
     ]
    }
   ],
   "source": [
    "connection_string =f'mysql+pymysql://{username}:{password}@{host}/{dbname}'\n",
    "print (connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45e03520-522c-4578-8fc9-39715159ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_engine=sqlalchemy.create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2d23177-d057-4dbc-ba28-3600d9f20ba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(pymysql.err.OperationalError) (1044, \"Access denied for user 'studente_dapt'@'%' to database 'AdventureWorks'\")\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:146\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3298\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3277\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3278\u001b[0m \n\u001b[0;32m   3279\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3296\u001b[0m \n\u001b[0;32m   3297\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    447\u001b[0m \n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionFairy\u001b[38;5;241m.\u001b[39m_checkout(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:1264\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1264\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m _ConnectionRecord\u001b[38;5;241m.\u001b[39mcheckout(pool)\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:713\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 713\u001b[0m     rec \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_do_get()\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:179\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionRecord(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:675\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 675\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__connect()\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:901\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    902\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:897\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_invoke_creator(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    898\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:646\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    644\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:622\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:365\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_key_password, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:681\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(self, sock)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_server_information()\n\u001b[1;32m--> 681\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_authentication()\n\u001b[0;32m    683\u001b[0m \u001b[38;5;66;03m# Send \"SET NAMES\" query on init for:\u001b[39;00m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;66;03m# - Ensure charaset (and collation) is set to the server.\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;66;03m#   - collation_id in handshake packet may be ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# - https://github.com/wagtail/wagtail/issues/9477\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# - https://zenn.dev/methane/articles/2023-mysql-collation (Japanese)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:958\u001b[0m, in \u001b[0;36mConnection._request_authentication\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_packet(data)\n\u001b[1;32m--> 958\u001b[0m auth_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_packet()\n\u001b[0;32m    960\u001b[0m \u001b[38;5;66;03m# if authentication method isn't accepted the first byte\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;66;03m# will have the octet 254\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:782\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 782\u001b[0m     packet\u001b[38;5;241m.\u001b[39mraise_for_error()\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\protocol.py:219\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[1;32m--> 219\u001b[0m err\u001b[38;5;241m.\u001b[39mraise_mysql_exception(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\err.py:150\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    149\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[1;31mOperationalError\u001b[0m: (1044, \"Access denied for user 'studente_dapt'@'%' to database 'AdventureWorks'\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselect * from dimproduct\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(query,db_engine)\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:704\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[0;32m    701\u001b[0m     dtype_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m--> 704\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[0;32m    707\u001b[0m             sql,\n\u001b[0;32m    708\u001b[0m             index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    714\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    715\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:906\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[1;34m(con, schema, need_transaction)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, (\u001b[38;5;28mstr\u001b[39m, sqlalchemy\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mConnectable)):\n\u001b[1;32m--> 906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SQLDatabase(con, schema, need_transaction)\n\u001b[0;32m    908\u001b[0m adbc \u001b[38;5;241m=\u001b[39m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madbc_driver_manager.dbapi\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adbc \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, adbc\u001b[38;5;241m.\u001b[39mConnection):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1636\u001b[0m, in \u001b[0;36mSQLDatabase.__init__\u001b[1;34m(self, con, schema, need_transaction)\u001b[0m\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39mcallback(con\u001b[38;5;241m.\u001b[39mdispose)\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, Engine):\n\u001b[1;32m-> 1636\u001b[0m     con \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(con\u001b[38;5;241m.\u001b[39mconnect())\n\u001b[0;32m   1637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_transaction \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m con\u001b[38;5;241m.\u001b[39min_transaction():\n\u001b[0;32m   1638\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(con\u001b[38;5;241m.\u001b[39mbegin())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3274\u001b[0m, in \u001b[0;36mEngine.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[0;32m   3253\u001b[0m \n\u001b[0;32m   3254\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3271\u001b[0m \n\u001b[0;32m   3272\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_cls(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:148\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 148\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[0;32m    149\u001b[0m             err, dialect, engine\n\u001b[0;32m    150\u001b[0m         )\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2439\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[1;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[0;32m   2437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2438\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2441\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:146\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    148\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[0;32m    149\u001b[0m             err, dialect, engine\n\u001b[0;32m    150\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:3298\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m   3277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[0;32m   3278\u001b[0m \n\u001b[0;32m   3279\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3296\u001b[0m \n\u001b[0;32m   3297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[0;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    447\u001b[0m \n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionFairy\u001b[38;5;241m.\u001b[39m_checkout(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:1264\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_checkout\u001b[39m(\n\u001b[0;32m   1258\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[1;32m-> 1264\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m _ConnectionRecord\u001b[38;5;241m.\u001b[39mcheckout(pool)\n\u001b[0;32m   1266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1267\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:713\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    711\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 713\u001b[0m     rec \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_do_get()\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:179\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[0;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ConnectionRecord(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:675\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[1;32m--> 675\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__connect()\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:901\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[0;32m    902\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\pool\\base.py:897\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39m_invoke_creator(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    898\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\create.py:646\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    644\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[1;32m--> 646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:622\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams):\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[1;32m--> 622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39mcargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:365\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[1;34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_key_password, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:681\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(self, sock)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_seq_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_server_information()\n\u001b[1;32m--> 681\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_authentication()\n\u001b[0;32m    683\u001b[0m \u001b[38;5;66;03m# Send \"SET NAMES\" query on init for:\u001b[39;00m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;66;03m# - Ensure charaset (and collation) is set to the server.\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;66;03m#   - collation_id in handshake packet may be ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;66;03m# - https://github.com/wagtail/wagtail/issues/9477\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# - https://zenn.dev/methane/articles/2023-mysql-collation (Japanese)\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_character_set(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollation)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:958\u001b[0m, in \u001b[0;36mConnection._request_authentication\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    955\u001b[0m     data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _lenenc_int(\u001b[38;5;28mlen\u001b[39m(connect_attrs)) \u001b[38;5;241m+\u001b[39m connect_attrs\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_packet(data)\n\u001b[1;32m--> 958\u001b[0m auth_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_packet()\n\u001b[0;32m    960\u001b[0m \u001b[38;5;66;03m# if authentication method isn't accepted the first byte\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;66;03m# will have the octet 254\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth_packet\u001b[38;5;241m.\u001b[39mis_auth_switch_request():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\connections.py:782\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 782\u001b[0m     packet\u001b[38;5;241m.\u001b[39mraise_for_error()\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\protocol.py:219\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[1;32m--> 219\u001b[0m err\u001b[38;5;241m.\u001b[39mraise_mysql_exception(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pymysql\\err.py:150\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[1;31mOperationalError\u001b[0m: (pymysql.err.OperationalError) (1044, \"Access denied for user 'studente_dapt'@'%' to database 'AdventureWorks'\")\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "query = 'select * from dimproduct'\n",
    "df = pd.read_sql(query,db_engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd846cfd-adb5-4f4c-818d-4aaafc62f878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34267ec0-7d8e-44fc-a241-89ae170a11da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8d111-021c-4ee6-a62e-102c0fb6c890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593a71f-1ce1-4377-811d-26fd01688ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cd8fe-4086-4c2c-88bd-8394d92b0200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e249b011-1883-44be-a2b9-cb6f383fdaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3a007-4078-4290-b3bf-1db7e67ce411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8d68429-ef89-4273-9d0a-5085ea5710e1",
   "metadata": {},
   "source": [
    "Esercizio \n",
    "Creiamo un DataFrame sintetico, che contiene i guadagni mensili di diverse annate, con il seguente codice: years = 5 guadagni = pd.DataFrame({\"Mese\": list(\"GFMAMGLASOND\"*years), \"Anno\": np.repeat(list(range(years)), 12), \"Valore\": np.random.randint(800, 5000, 12*years)}) \n",
    "\n",
    "• Calcola la somma cumulativa dei guadagni utilizzando il metodo .cumsum() \n",
    "• Come sopra, ma raggruppato per ogni anno usando prima un .groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a489402a-a0b0-4f57-bf0c-a573b89e1ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mese  Anno  Valore  Somma_Cumulativa\n",
      "0     G     0    2703              2703\n",
      "1     F     0    4832              7535\n",
      "2     M     0    3290             10825\n",
      "3     A     0    4975             15800\n",
      "4     M     0    4483             20283\n",
      "5     G     0    2684             22967\n",
      "6     L     0    4661             27628\n",
      "7     A     0    2314             29942\n",
      "8     S     0    3501             33443\n",
      "9     O     0    3631             37074\n",
      "10    N     0    2665             39739\n",
      "11    D     0     998             40737\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "years = 5\n",
    "guadagni = pd.DataFrame({\n",
    "    'Mese': list(\"GFMAMGLASOND\" * years), \n",
    "    \"Anno\": np.repeat(list(range(years)), 12), \n",
    "    \"Valore\": np.random.randint(800, 5000, 12 * years)\n",
    "})\n",
    "\n",
    "# somma cumulativa dei guadagni\n",
    "guadagni['Somma_Cumulativa'] = guadagni['Valore'].cumsum()\n",
    "\n",
    "print(guadagni.head(12))  # mostriamo i primi 15 record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "267fb086-b7a5-4cb7-a0b1-a2becbe02fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mese  Anno  Valore  Somma_Cumulativa\n",
      "0     G     0    3857              3857\n",
      "1     F     0    2789              6646\n",
      "2     M     0    1181              7827\n",
      "3     A     0    3095             10922\n",
      "4     M     0    1550             12472\n",
      "5     G     0    1632             14104\n",
      "6     L     0    3318             17422\n",
      "7     A     0    1692             19114\n",
      "8     S     0    1195             20309\n",
      "9     O     0     898             21207\n",
      "10    N     0    2549             23756\n",
      "11    D     0    4148             27904\n",
      "12    G     1    4973              4973\n",
      "13    F     1    1200              6173\n"
     ]
    }
   ],
   "source": [
    "#• Come sopra, ma raggruppato per ogni anno usando prima un .groupby()\n",
    "years = 5\n",
    "guadagni = pd.DataFrame({\n",
    "    'Mese': list(\"GFMAMGLASOND\" * years), \n",
    "    \"Anno\": np.repeat(list(range(years)), 12), \n",
    "    \"Valore\": np.random.randint(800, 5000, 12 * years)\n",
    "})\n",
    "\n",
    "# somma cumulativa dei guadagni per anno\n",
    "guadagni['Somma_Cumulativa'] = guadagni.groupby('Anno')['Valore'].cumsum()\n",
    "\n",
    "print(guadagni.head(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4682ddd1-9a71-465d-b0b9-f5adfc07f3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2873175-80d9-4ddb-9ad0-ee0b0555edba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f5b1a-9558-4a24-802f-f3214f1e5bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac3ee6-c0c6-4dc1-92a2-932a126250e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4469dd41-970d-4e05-94fc-e7669ae4f656",
   "metadata": {},
   "source": [
    "Esercizio 1/2\n",
    "Dal database AdventureWorks estraiamo la tabella dimcustomer \n",
    "• Trasformiamo i nomi dei clienti in modo che abbiano solo lettere minuscole, e i cognomi in modo che abbiano solo lettere maiuscole \n",
    "• Sulla colonna EmailAddress, utilizzando il metodo .str.split(), estraiamo nome utente e dominio • Sulla colonna Phone, estraiamo ogni parte del numero (ad es. da \"1 (11) 500 555-0162\" a [\"1\", \"(11)\", \"500\", \"555-0162\"]) \n",
    "• Utilizzando il metodo .str.contains(), estraiamo tutti gli indirizzi e-mail che contengono il numero \"21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2927319-e197-425e-91b0-6f67acef8c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4bbf43-0884-4290-835f-bfe24f5fb2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a056ce-f85b-4114-a0e5-3eaac0fe08f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bfd5af-b643-489c-ada2-12e1394755d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec394bb-4ed6-4f11-9f18-067f9ff4493a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba7cd9-dd97-405b-8fd4-6d1d755d981a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8b8c143-a9c9-43c4-99b6-7658b0ff1e30",
   "metadata": {},
   "source": [
    "Esercizio 2/2\n",
    "• Estraiamo tutti gli indirizzi e-mail che contengono il numero \"20\" oppure il numero \"10\" \n",
    "• Calcolare la lunghezza di ogni indirizzo e-mail ed estrarre i cinque più lunghi e i cinque più corti \n",
    "• Modificare il dominio degli indirizzi e-mail da \"adventure-works.com\" a \"aw-db.com\" mediante il metodo .str.replace() \n",
    "• Dalla colonna AddressLine1 estraiamo tutti gli indirizzi che contengono la sottostringa \"Street\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15ffcf-eeee-4f12-a6b6-13d48139186b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd44c0-7b44-480c-b0c3-2e06d73a7d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d6241-c981-473c-9e4d-c796157cdd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce021a5-d6d6-4204-9d38-4ea34219517d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78007f-635c-4472-90b9-067ce7375040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2406b38-f959-42d4-a414-105942c47dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54fcf3d6-cca9-4462-a24a-bcde5dc9bd2f",
   "metadata": {},
   "source": [
    "Esercizio 1/2 \n",
    "Dai beginner_datasets carichiamo in un DataFrame il file facebook.csv, che contiene dei post con data di pubblicazione, tipo (foto, video, …) e numero di reactions raccolte: \n",
    "• Con la funzione pd.to_datetime() convertiamo la colonna status_published in formato Timestamp \n",
    "• Utilizzando gli attributi .dt.year , .dt.month , .dt.day , .dt.dayofweek , .dt.dayofyear, ottieniamo informazioni specifiche sulle date delle transazioni, come l'anno, il mese, il giorno della settimana, il giorno dell'anno, eccetera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a36f720-ac25-4287-afa5-723c497bdc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status_id                   object\n",
      "status_type                 object\n",
      "status_published    datetime64[ns]\n",
      "num_reactions                int64\n",
      "num_comments                 int64\n",
      "num_shares                   int64\n",
      "num_likes                    int64\n",
      "num_loves                    int64\n",
      "num_wows                     int64\n",
      "num_hahas                    int64\n",
      "num_sads                     int64\n",
      "num_angrys                   int64\n",
      "dtype: object\n",
      "                          status_id status_type    status_published  \\\n",
      "0  246675545449582_1649696485147474       video 2018-04-22 06:00:00   \n",
      "1  246675545449582_1649426988507757       photo 2018-04-21 22:45:00   \n",
      "2  246675545449582_1648730588577397       video 2018-04-21 06:17:00   \n",
      "3  246675545449582_1648576705259452       photo 2018-04-21 02:29:00   \n",
      "4  246675545449582_1645700502213739       photo 2018-04-18 03:22:00   \n",
      "\n",
      "   num_reactions  num_comments  num_shares  num_likes  num_loves  num_wows  \\\n",
      "0            529           512         262        432         92         3   \n",
      "1            150             0           0        150          0         0   \n",
      "2            227           236          57        204         21         1   \n",
      "3            111             0           0        111          0         0   \n",
      "4            213             0           0        204          9         0   \n",
      "\n",
      "   num_hahas  num_sads  num_angrys  \n",
      "0          1         1           0  \n",
      "1          0         0           0  \n",
      "2          1         0           0  \n",
      "3          0         0           0  \n",
      "4          0         0           0  \n"
     ]
    }
   ],
   "source": [
    "#Con la funzione pd.to_datetime() convertiamo la colonna status_published in formato Timestamp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. il dataset\n",
    "df = pd.read_csv(\"facebook.csv\")\n",
    "\n",
    "# 2. Conversione della colonna 'status_published' in formato Timestamp\n",
    "df[\"status_published\"] = pd.to_datetime(df[\"status_published\"])\n",
    "\n",
    "# 3. risultato\n",
    "print(df.dtypes)        \n",
    "print(df.head())\n",
    "# mostra i tipi di dato delle colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f104947-3a67-4550-9775-b19cf573a20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          status_id status_type    status_published  \\\n",
      "0  246675545449582_1649696485147474       video 2018-04-22 06:00:00   \n",
      "1  246675545449582_1649426988507757       photo 2018-04-21 22:45:00   \n",
      "2  246675545449582_1648730588577397       video 2018-04-21 06:17:00   \n",
      "3  246675545449582_1648576705259452       photo 2018-04-21 02:29:00   \n",
      "4  246675545449582_1645700502213739       photo 2018-04-18 03:22:00   \n",
      "\n",
      "   num_reactions  num_comments  num_shares  num_likes  num_loves  num_wows  \\\n",
      "0            529           512         262        432         92         3   \n",
      "1            150             0           0        150          0         0   \n",
      "2            227           236          57        204         21         1   \n",
      "3            111             0           0        111          0         0   \n",
      "4            213             0           0        204          9         0   \n",
      "\n",
      "   num_hahas  num_sads  num_angrys  Anno  Mese  Giorno  Giorno_settimana  \\\n",
      "0          1         1           0  2018     4      22                 6   \n",
      "1          0         0           0  2018     4      21                 5   \n",
      "2          1         0           0  2018     4      21                 5   \n",
      "3          0         0           0  2018     4      21                 5   \n",
      "4          0         0           0  2018     4      18                 2   \n",
      "\n",
      "   Giorno_anno  \n",
      "0          112  \n",
      "1          111  \n",
      "2          111  \n",
      "3          111  \n",
      "4          108  \n"
     ]
    }
   ],
   "source": [
    "#• Utilizzando gli attributi .dt.year , .dt.month , .dt.day , .dt.dayofweek , .dt.dayofyear, \n",
    "#ottieniamo informazioni specifiche sulle date delle transazioni, come l'anno, il mese, il giorno della settimana, il giorno dell'anno, eccetera\n",
    "df = pd.read_csv('facebook.csv')\n",
    "\n",
    "# Convertire la colonna in Timestamp\n",
    "df['status_published'] = pd.to_datetime(df['status_published'])\n",
    "\n",
    "# Creo nuove colonne con attributi .dt\n",
    "df['Anno'] = df['status_published'].dt.year\n",
    "df['Mese'] = df['status_published'].dt.month\n",
    "df['Giorno'] = df['status_published'].dt.day\n",
    "df['Giorno_settimana'] = df['status_published'].dt.dayofweek   # 0 = lunedì, 6 = domenica\n",
    "df['Giorno_anno'] = df['status_published'].dt.dayofyear\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a676c-d5dc-495a-b7a0-91d39c70a920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6779c1-7843-47a7-bc12-fa0a1157b710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0813e-f60d-45c9-ac91-bf5dcfb212dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84289f13-a4f8-4d8a-933f-1ee215411e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "674a77f3-23c2-4c40-9e9c-3aa77fe608ba",
   "metadata": {},
   "source": [
    "Esercizio 2/2 \n",
    "• Estraiamo solo i post relativi al 2012 \n",
    "• Estraiamo solo i post relativi a maggio 2018 • Confrontiamo il numero di post pubblicati nei weekend rispetto al numero di post pubblicati nel resto della settimana \n",
    "• Troviamo il primo e ultimo post pubblicati in ogni anno • Quanti tipi di post ci sono? E quanti per ogni tipo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a824a34-85b1-42f9-8da9-8f36f04a2c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            status_id status_type    status_published  \\\n",
      "2046  246675545449582_303160673134402       photo 2012-12-23 03:11:00   \n",
      "\n",
      "      num_reactions  num_comments  num_shares  num_likes  num_loves  num_wows  \\\n",
      "2046              0             0           0          0          0         0   \n",
      "\n",
      "      num_hahas  num_sads  num_angrys  Anno  Mese  Giorno  Giorno_settimana  \\\n",
      "2046          0         0           0  2012    12      23                 6   \n",
      "\n",
      "      Giorno_anno  giorno_settimana  \n",
      "2046          358                 6  \n",
      "                            status_id status_type    status_published  \\\n",
      "2634  246675545449582_246677465449390       photo 2012-07-15 02:51:00   \n",
      "\n",
      "      num_reactions  num_comments  num_shares  num_likes  num_loves  num_wows  \\\n",
      "2634             15             3           0         15          0         0   \n",
      "\n",
      "      num_hahas  num_sads  num_angrys  Anno  Mese  Giorno  Giorno_settimana  \\\n",
      "2634          0         0           0  2012     7      15                 6   \n",
      "\n",
      "      Giorno_anno  giorno_settimana  \n",
      "2634          197                 6  \n"
     ]
    }
   ],
   "source": [
    "post_2012 = df[df[\"status_published\"].dt.year == 2012]\n",
    "print(post_2012.head(1))\n",
    "print(post_2012.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "103507b8-0393-4ae2-a0f5-8a0a366a9bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            status_id status_type    status_published  \\\n",
      "2690  134115277150304_264554297439734       photo 2018-05-31 12:17:00   \n",
      "2691  134115277150304_264493694112461       photo 2018-05-31 08:37:00   \n",
      "2692  134115277150304_264416247453539       photo 2018-05-31 03:12:00   \n",
      "2693  134115277150304_264168277478336       photo 2018-05-30 08:46:00   \n",
      "2694  134115277150304_264160757479088       photo 2018-05-30 08:24:00   \n",
      "2695  134115277150304_264104020818095       photo 2018-05-30 05:09:00   \n",
      "\n",
      "      num_reactions  num_comments  num_shares  num_likes  num_loves  num_wows  \\\n",
      "2690             11             0           0         10          0         1   \n",
      "2691             56             4           2         55          1         0   \n",
      "2692             72            13           1         69          3         0   \n",
      "2693             10             0           0         10          0         0   \n",
      "2694             56             3          12         54          2         0   \n",
      "2695             45             0           3         44          1         0   \n",
      "\n",
      "      num_hahas  num_sads  num_angrys  Anno  Mese  Giorno  Giorno_settimana  \\\n",
      "2690          0         0           0  2018     5      31                 3   \n",
      "2691          0         0           0  2018     5      31                 3   \n",
      "2692          0         0           0  2018     5      31                 3   \n",
      "2693          0         0           0  2018     5      30                 2   \n",
      "2694          0         0           0  2018     5      30                 2   \n",
      "2695          0         0           0  2018     5      30                 2   \n",
      "\n",
      "      Giorno_anno  \n",
      "2690          151  \n",
      "2691          151  \n",
      "2692          151  \n",
      "2693          150  \n",
      "2694          150  \n",
      "2695          150  \n"
     ]
    }
   ],
   "source": [
    "post_maggio_2018 = df[\n",
    "    (df[\"status_published\"].dt.year == 2018) &\n",
    "    (df[\"status_published\"].dt.month == 5)\n",
    "]\n",
    "print(post_maggio_2018.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "343951be-29c9-4458-b881-9306059e6020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post nei weekend: 2041\n",
      "Post nei giorni feriali: 5009\n"
     ]
    }
   ],
   "source": [
    "# 0 = lunedì, ..., 6 = domenica\n",
    "df[\"giorno_settimana\"] = df[\"status_published\"].dt.dayofweek\n",
    "\n",
    "weekend = df[df[\"giorno_settimana\"].isin([5, 6])]\n",
    "feriali = df[~df[\"giorno_settimana\"].isin([5, 6])]\n",
    "\n",
    "print(\"Post nei weekend:\", len(weekend))\n",
    "print(\"Post nei giorni feriali:\", len(feriali))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ecfae02-bf58-450d-970d-44f80ffa7ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primo post per anno:\n",
      " status_published\n",
      "2012   2012-07-15 02:51:00\n",
      "2013   2013-01-02 02:23:00\n",
      "2014   2014-01-05 09:23:00\n",
      "2015   2015-01-02 03:41:00\n",
      "2016   2016-01-03 04:23:00\n",
      "2017   2017-01-02 08:25:00\n",
      "2018   2018-01-01 01:39:00\n",
      "Name: status_published, dtype: datetime64[ns]\n",
      "Ultimo post per anno:\n",
      " status_published\n",
      "2012   2012-12-23 03:11:00\n",
      "2013   2013-12-31 23:38:00\n",
      "2014   2014-12-10 07:42:00\n",
      "2015   2015-12-31 08:20:00\n",
      "2016   2016-12-31 05:13:00\n",
      "2017   2017-12-31 22:15:00\n",
      "2018   2018-06-13 01:12:00\n",
      "Name: status_published, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "primo_post = df.groupby(df[\"status_published\"].dt.year)[\"status_published\"].min()\n",
    "ultimo_post = df.groupby(df[\"status_published\"].dt.year)[\"status_published\"].max()\n",
    "\n",
    "print(\"Primo post per anno:\\n\", primo_post)\n",
    "print(\"Ultimo post per anno:\\n\", ultimo_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8581f5e8-11f1-41e9-b642-b35c2330dd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipi di post: ['video' 'photo' 'link' 'status']\n",
      "Conteggio per tipo:\n",
      " status_type\n",
      "photo     4288\n",
      "video     2334\n",
      "status     365\n",
      "link        63\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Tipi di post:\", df[\"status_type\"].unique())\n",
    "print(\"Conteggio per tipo:\\n\", df[\"status_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd8994-5dfe-4a2e-b769-9367ed0d0bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f1d5c-8646-4560-b3dc-27490e7cf693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "247a5095-7e5f-48a1-9dcd-748efcf2db62",
   "metadata": {},
   "source": [
    "Esercizio Dai beginner_dataset carichiamo in un DataFrame il file pokemon.csv:\n",
    "• Tramite i metodi .isnull() e .sum() controlliamo se ci sono valori nulli nel dataset e contiamo quanti valori nulli ci sono in ogni colonna\n",
    "• Ci sono valori nulli? \n",
    "• Se sì, avrebbe senso cercare di riempirli? • Eliminiamo le righe che contengono valori nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbd0541b-0f4b-4041-a374-0bb5442a5efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valori nulli per colonna:\n",
      " Num             0\n",
      "Name            0\n",
      "Type1           0\n",
      "Type2         386\n",
      "HP              0\n",
      "Attack          0\n",
      "Defense         0\n",
      "SpAtk           0\n",
      "SpDef           0\n",
      "Speed           0\n",
      "Generation      0\n",
      "Legendary       0\n",
      "dtype: int64\n",
      "\n",
      "Ci sono valori nulli? True\n",
      "\n",
      "Dimensioni originali: (800, 12)\n",
      "Dimensioni dopo dropna: (414, 12)\n"
     ]
    }
   ],
   "source": [
    "# 1. Carichiamo il dataset\n",
    "df = pd.read_csv(\"pokemonData.csv\")\n",
    "\n",
    "# 2. Controlliamo se ci sono valori nulli\n",
    "null_check = df.isnull().sum()\n",
    "print(\"Valori nulli per colonna:\\n\", null_check)\n",
    "\n",
    "# 3. Verifichiamo se ci sono valori nulli\n",
    "print(\"\\nCi sono valori nulli?\", df.isnull().values.any())\n",
    "\n",
    "# 4. Se ci sono valori nulli, valutiamo se riempirli\n",
    "# (dipende dal contesto: ad esempio, se mancano valori numerici come 'Attack',\n",
    "# potremmo sostituirli con la media o la mediana. Se mancano nomi, potremmo lasciarli vuoti.)\n",
    "\n",
    "# 5. Eliminiamo le righe che contengono valori nulli\n",
    "df_clean = df.dropna()\n",
    "\n",
    "print(\"\\nDimensioni originali:\", df.shape)\n",
    "print(\"Dimensioni dopo dropna:\", df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2105b6ad-25c6-487c-92e1-b6ab44ded685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e578c-edf3-409e-ab4c-1a6f07774019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7060ef-d7f1-48e3-a827-d59905ed4e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daa56161-4339-42c4-a5ef-7efbcfab0c52",
   "metadata": {},
   "source": [
    "Esercizio Dai beginner_dataset carichiamo in un DataFrame il file automobile.csv: \n",
    "• Ci sono valori nulli? Dove? Quanti? \n",
    "• Quali righe hanno un valore nullo nella colonna num-of-doors? \n",
    "• Esaminando i dati nel dataset, cerchiamo una logica per sostituire i valori nulli nella colonna num-of-doors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7cc765d3-0d22-49b8-b958-89ee70d3a2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valori nulli per colonna:\n",
      " symboling             0\n",
      "normalized-losses    37\n",
      "make                  0\n",
      "fuel-type             0\n",
      "aspiration            0\n",
      "num-of-doors          2\n",
      "body-style            0\n",
      "drive-wheels          0\n",
      "engine-location       0\n",
      "wheel-base            0\n",
      "length                0\n",
      "width                 0\n",
      "height                0\n",
      "curb-weight           0\n",
      "engine-type           0\n",
      "num-of-cylinders      0\n",
      "engine-size           0\n",
      "fuel-system           0\n",
      "bore                  0\n",
      "stroke                0\n",
      "compression-ratio     0\n",
      "horsepower            0\n",
      "peak-rpm              0\n",
      "city-mpg              0\n",
      "highway-mpg           0\n",
      "price                 0\n",
      "dtype: int64\n",
      "\n",
      "Ci sono valori nulli? True\n",
      "\n",
      "Righe con valori nulli in num-of-doors:\n",
      "     symboling  normalized-losses   make fuel-type aspiration num-of-doors  \\\n",
      "26          1              148.0  dodge       gas      turbo          NaN   \n",
      "60          0                NaN  mazda    diesel        std          NaN   \n",
      "\n",
      "   body-style drive-wheels engine-location  wheel-base  ...  engine-size  \\\n",
      "26      sedan          fwd           front        93.7  ...           98   \n",
      "60      sedan          fwd           front        98.8  ...          122   \n",
      "\n",
      "    fuel-system  bore  stroke compression-ratio horsepower  peak-rpm city-mpg  \\\n",
      "26         mpfi  3.03    3.39               7.6        102      5500       24   \n",
      "60          idi  3.39    3.39              22.7         64      4650       36   \n",
      "\n",
      "   highway-mpg  price  \n",
      "26          30   8558  \n",
      "60          42  10795  \n",
      "\n",
      "[2 rows x 26 columns]\n",
      "\n",
      "Distribuzione num-of-doors per body-style:\n",
      " body-style   num-of-doors\n",
      "convertible  two              6\n",
      "hardtop      two              8\n",
      "hatchback    two             58\n",
      "             four            10\n",
      "sedan        four            79\n",
      "             two             14\n",
      "wagon        four            25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Carichiamo il dataset\n",
    "df = pd.read_csv(\"automobile.csv\")\n",
    "\n",
    "# 2. Controlliamo i valori nulli per colonna\n",
    "null_counts = df.isnull().sum()\n",
    "print(\"Valori nulli per colonna:\\n\", null_counts)\n",
    "\n",
    "# 3. Verifichiamo se ci sono valori nulli\n",
    "print(\"\\nCi sono valori nulli?\", df.isnull().values.any())\n",
    "\n",
    "# 4. Individuiamo le righe con valori nulli in 'num-of-doors'\n",
    "rows_with_null_doors = df[df['num-of-doors'].isnull()]\n",
    "print(\"\\nRighe con valori nulli in num-of-doors:\\n\", rows_with_null_doors)\n",
    "\n",
    "# 5. Possibile logica per sostituire i valori nulli\n",
    "# Ad esempio: guardiamo la colonna 'body-style' per capire se è più probabile 2 o 4 porte\n",
    "print(\"\\nDistribuzione num-of-doors per body-style:\\n\", df.groupby('body-style')['num-of-doors'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a01e9d30-d8a0-4250-84d8-a0db0ebc38ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valori nulli dopo sostituzione:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "# Sostituiamo i valori nulli in num-of-doors con 'four' se body-style è sedan\n",
    "df.loc[(df['num-of-doors'].isnull()) & (df['body-style'] == 'sedan'), 'num-of-doors'] = 'four'\n",
    "\n",
    "# Controlliamo di nuovo\n",
    "print(\"\\nValori nulli dopo sostituzione:\\n\", df['num-of-doors'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96c390-9f46-4219-b26f-9e0b8b2f03b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc74afa-f613-4f04-9c5b-4075f9dea728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8f931f-d250-4b80-98e0-56338c074fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e7e37-fc99-4f49-af60-0980ca1f3756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10f904e9-6808-4460-a098-2a482366c3f5",
   "metadata": {},
   "source": [
    "Esercizio Abbiamo il seguente DataFrame che raccoglie le misurazioni di un sensore che misura la temperatura atmosferica giornaliera: import numpy as np, pandas as pd temp = pd.DataFrame({\"Giorno\": [0, 1, 2, 3, 4, 5, 6 7, 8, 9, 10, 11, 12], \"Temperature\": [18, 19, 18, np.nan, 21, 20, 20, np.nan, 21, 23, np.nan, 23, 24]}) • Il sensore a volte non funziona, dunque alcuni dati sono mancanti: quale sarebbe la migliore strategia per gestirli? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "35914385-a075-4678-90a2-bcb6f0a73c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "temp = pd.DataFrame({\"Giorno\": [0, 1, 2, 3, 4, 5, 6,7, 8, 9, 10, 11, 12], \n",
    "                     \"Temperature\": [18, 19, 18, np.nan, 21, 20, 20, np.nan, 21, 23, np.nan, 23, 24]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f4ea3ed0-226f-4187-834d-252527047156",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_clean = temp.dropna()\n",
    "#Eliminare le righe con valori nulli (dropna)\n",
    "#Semplice e veloce\n",
    "\n",
    "#Rischi di perdere informazioni preziose, soprattutto se i dati mancanti non sono pochi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bbce97-611a-4c01-bbc7-6d35c5cbb2fc",
   "metadata": {},
   "source": [
    "Esercizio 1/2 Nel pacchetto os della standard library c'è la funzione os.listdir() che permette di avere la lista dei nomi di file all'interno di una directory; senza input di default li cerca nella directory di lavoro corrente, altrimenti si può passare un path per esaminare una directory specifica, ad esempio os.listdir(\"mio_progetto/beginner_datasets/\") • Nella directory dei beginner_datasets, quali sono i dataset che contengono dati nulli?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93651cdf-52b3-401a-a7fc-ab68f8b28063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da5af58-92f8-42f1-8c2a-ff3c5344ccfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e5aa1-b996-4d44-ac7a-1b801c05b74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a025be-d7d2-4f69-8554-16b2b1ba80c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10879338-7b3a-4953-9e3e-7bc6546760d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e7ed72-15fd-4955-bb07-ed77f6476a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
